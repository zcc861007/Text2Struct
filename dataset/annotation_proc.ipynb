{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1-NGFxgHwDG8-Iv5GijNgAzatLD5s_mli","authorship_tag":"ABX9TyPCnFEqZbeC0+AoC1TeNAVS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os, sys\n","\n","workspace = '/content/drive/MyDrive/Colab Notebooks/Text2Struct/'\n","print(os.path.exists(workspace))\n","\n","modules_dir = workspace + 'modules/'\n","sys.path.insert(0, modules_dir)\n","\n","data_dir = workspace + 'dataset/annotated/thrombectomy_0-99/'\n","out_dir = workspace + 'dataset/combined/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ceE7aeIYpgVy","executionInfo":{"status":"ok","timestamp":1670985798933,"user_tz":360,"elapsed":3,"user":{"displayName":"Chaochao Zhou","userId":"12741515649526346331"}},"outputId":"e540fa60-68d8-4c55-f0e8-ae4433d48393"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","source":["import brat_parser\n","import pathlib\n","import nltk\n","nltk.download('punkt')\n","import numpy as np\n","import pickle"],"metadata":{"id":"4chslDHCp0sQ","executionInfo":{"status":"ok","timestamp":1670985802323,"user_tz":360,"elapsed":1905,"user":{"displayName":"Chaochao Zhou","userId":"12741515649526346331"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"21e13085-bc65-46e1-ce4a-03f3188477ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["# Annotation processing"],"metadata":{"id":"EVm-7eOxDULV"}},{"cell_type":"code","source":["def spans(txt):\n","    # tokens = nltk.word_tokenize(txt)  # note: it wrongly changes quotes\n","    tokens = txt.split()\n","    offset = 0\n","    for token in tokens:\n","        offset = txt.find(token, offset)\n","        yield token, offset, offset+len(token)\n","        assert token == txt[offset:offset+len(token)]\n","        offset += len(token)\n","\n","# ## Checking\n","# s = 'Following time intervals were shortened in comparison to 2016 : \" hospital arrival - GP \" ( 77 vs. 53 min ; p < 0.0001 ).'\n","# print(s)\n","# for token in spans(s):\n","#     print(token)\n","#     # assert token[0]==s[token[1]:token[2]]"],"metadata":{"id":"Ggoaz2Rv0SGR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# folder_list = [os.path.join(data_dir, f) for f in sorted(os.listdir(data_dir)) \n","#                if not os.path.isfile(os.path.join(data_dir, f))]\n","# folder_list;\n","\n","# folder_dir = folder_list[51]\n","# sentence_names = [pathlib.Path(f).stem for f in sorted(os.listdir(folder_dir))\n","#                  if pathlib.Path(f).suffix == '.txt']\n","# sentence_names\n","\n","# sentence_name = sentence_names[5]\n","\n","# sentence_name"],"metadata":{"id":"SHYg_gARqlL2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def n_upper_chars(string):\n","    return sum(1 for c in string if c.isupper())"],"metadata":{"id":"g0LbfoMMW8d3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ## Extract content\n","# txt_path = os.path.join(folder_dir, sentence_name + '.txt')\n","# f = open(txt_path, 'r')\n","# content = f.read()\n","# print(content)\n","\n","# tokens_and_spans = [t for t in spans(content)]\n","# print(tokens_and_spans)\n","\n","# # tokens = [t[0] for t in tokens_and_spans]\n","# tokens = []\n","# for t in tokens_and_spans:\n","#   token = t[0]\n","#   if token[0].isupper() and n_upper_chars(token) < 2:\n","#     token = token.lower()\n","#   tokens.append(token)\n","\n","# tokens = np.array(tokens)\n","# print(tokens)"],"metadata":{"id":"cA_WaIMJ9Rcs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tokens_and_spans"],"metadata":{"id":"E6sgxVdFg0A8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ## Extract annotations\n","# ann_path = os.path.join(folder_dir, sentence_name + '.ann')\n","# entities, relations, attributes, groups = brat_parser.get_entities_relations_attributes_groups(ann_path)"],"metadata":{"id":"JGOOqkymxgTY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# entities"],"metadata":{"id":"Z_ZexDm7vldQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# relations"],"metadata":{"id":"639WhZuo32uz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def char2tok_span_convert(tokens_and_spans, char_span):\n","  tok_span = []\n","  for (i, ts) in enumerate(tokens_and_spans):\n","    if ts[1] >= char_span[0] and ts[2] <= char_span[1]:\n","      tok_span.append(i)\n","\n","  return tok_span\n","\n","# ## Checking\n","# char2tok_span_convert(tokens_and_spans, (66, 87))"],"metadata":{"id":"X3-zF01FyvEm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def entities_proc(entities, tokens_and_spans):\n","  ent_dict = {}\n","  for e in entities.keys():\n","    ent = entities[e]\n","    char_span = ent.span[0]\n","    tok_span = char2tok_span_convert(tokens_and_spans, char_span)\n","    ent_dict[e] = [ent.type, tok_span]\n","\n","  return ent_dict\n","\n","# ## Checking\n","# entities_proc(entities, tokens_and_spans)  "],"metadata":{"id":"6fQ-f6356B0a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def relations_proc(relations):\n","  rel_dict = {}\n","  for r in relations.keys():\n","    rel = relations[r]\n","    if rel.subj not in rel_dict.keys():\n","      rel_dict[rel.subj] = [rel.obj]\n","    else:\n","      rel_dict[rel.subj].append(rel.obj)\n","\n","  return rel_dict\n","\n","# ## Checking\n","# relations_proc(relations)"],"metadata":{"id":"fXKq6zEV91CJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def check_numeral(string):\n","  try:\n","      float(string)\n","      return True\n","  except ValueError:\n","      return False"],"metadata":{"id":"dbehmS4vEuLn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# entitites_dict = entities_proc(entities, tokens_and_spans)\n","# relations_dict = relations_proc(relations)\n","\n","# sentence_examples = []\n","\n","# for ent_key in entitites_dict.keys():\n","#   if entitites_dict[ent_key][0] == 'Num' and check_numeral(tokens[entitites_dict[ent_key][1][0]]): \n","#     example = {'cont': tokens, 'num': entitites_dict[ent_key][1], 'unit': [], 'targ': []}\n","#     if ent_key in relations_dict.keys():\n","#       obj_names = relations_dict[ent_key]\n","#       for name in obj_names:\n","#         if entitites_dict[name][0] == 'Unit':\n","#           example['unit'] = entitites_dict[name][1]\n","#         elif entitites_dict[name][0] == 'Targ':\n","#           example['targ'] = entitites_dict[name][1]\n","#     if example: sentence_examples.append(example)\n","\n","# sentence_examples"],"metadata":{"id":"3KLq0d5fIYI0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_examples_from_one_sentence(folder_dir, sentence_name):\n","  ## Extract content\n","  txt_path = os.path.join(folder_dir, sentence_name + '.txt')\n","  f = open(txt_path, 'r')\n","  content = f.read()\n","\n","  tokens_and_spans = [t for t in spans(content)]\n","  # tokens = [t[0] for t in tokens_and_spans]\n","  tokens = []\n","  for t in tokens_and_spans:\n","    token = t[0]\n","    if token[0].isupper() and n_upper_chars(token) < 2:\n","      token = token.lower()\n","    tokens.append(token)  \n","  tokens = np.array(tokens)\n","\n","  ## Extract annotations\n","  ann_path = os.path.join(folder_dir, sentence_name + '.ann')\n","  entities, relations, _, _ = brat_parser.get_entities_relations_attributes_groups(ann_path) \n","\n","  entitites_dict = entities_proc(entities, tokens_and_spans)\n","  relations_dict = relations_proc(relations)\n","\n","  ## Generate examples\n","  sentence_examples = []\n","\n","  for ent_key in entitites_dict.keys():\n","    if entitites_dict[ent_key][0] == 'Num' and check_numeral(tokens[entitites_dict[ent_key][1][0]]): \n","      example = {'cont': tokens, 'num': entitites_dict[ent_key][1], 'unit': [], 'targ': []}\n","      if ent_key in relations_dict.keys():\n","        obj_names = relations_dict[ent_key]\n","        for name in obj_names:\n","          if entitites_dict[name][0] == 'Unit':\n","            example['unit'] = entitites_dict[name][1]\n","          elif entitites_dict[name][0] == 'Targ':\n","            example['targ'] = entitites_dict[name][1]\n","      sentence_examples.append(example)  \n","  \n","  return sentence_examples\n","\n","# ## Checking\n","# extract_examples_from_one_sentence(folder_dir, sentence_name)"],"metadata":{"id":"4SoDcbhrA7-Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corpus_examples = []\n","# N = 0\n","\n","folder_list = [os.path.join(data_dir, f) for f in sorted(os.listdir(data_dir)) \n","               if not os.path.isfile(os.path.join(data_dir, f))]\n","\n","for (i, folder_dir) in enumerate(folder_list):\n","  sentence_names = [pathlib.Path(f).stem for f in sorted(os.listdir(folder_dir))\n","                    if pathlib.Path(f).suffix == '.txt']\n","\n","  for (j, sentence_name) in enumerate(sentence_names):\n","    # ann_path = os.path.join(folder_dir, sentence_name + '.ann')\n","    # entities, relations, _, _ = brat_parser.get_entities_relations_attributes_groups(ann_path)\n","    # N += len(relations)\n","\n","    sentence_examples = extract_examples_from_one_sentence(folder_dir, sentence_name)\n","    if sentence_examples: corpus_examples += sentence_examples # if not empty"],"metadata":{"id":"jCJkEXbITd6z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(corpus_examples), i, folder_dir, j, sentence_name"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzVzsEieXEAa","executionInfo":{"status":"ok","timestamp":1670985867000,"user_tz":360,"elapsed":109,"user":{"displayName":"Chaochao Zhou","userId":"12741515649526346331"}},"outputId":"36eef288-04cf-4262-ce74-a02e32c280c9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1758,\n"," 87,\n"," '/content/drive/MyDrive/Colab Notebooks/Text2Struct/dataset/annotated/thrombectomy_0-99/PMID_36227897',\n"," 3,\n"," 'S_8')"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["for example in corpus_examples:\n","  if type(example) != dict:\n","    print(type(example))"],"metadata":{"id":"wvc8t63ofBG7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example = corpus_examples[np.random.choice(len(corpus_examples))]\n","content = example['cont']\n","print(content)\n","print('Sentence length is:', len(content))\n","print()\n","print('Numeral is:', content[example['num']])\n","print('Unit is: ', content[example['unit']])\n","print('Target is:', content[example['targ']])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JAMGTbTrjLkC","executionInfo":{"status":"ok","timestamp":1670985877741,"user_tz":360,"elapsed":93,"user":{"displayName":"Chaochao Zhou","userId":"12741515649526346331"}},"outputId":"0e95decd-84f7-4258-8a6c-b9818b4770e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['there' 'were' '1227' 'patients' '(' '0.499' ')' 'in' 'the' 'DEVT'\n"," 'group' 'and' '1233' 'patients' '(' '0.501' ')' 'in' 'the' 'BT' 'group'\n"," '.']\n","Sentence length is: 22\n","\n","Numeral is: ['1227']\n","Unit is:  ['patients']\n","Target is: ['DEVT' 'group']\n"]}]},{"cell_type":"code","source":["## Save data\n","# filehandler = open(data_dir + \"corpus_examples.pkl\", \"wb\")\n","filehandler = open(out_dir + \"corpus_examples.pkl\", \"wb\")\n","pickle.dump(corpus_examples, filehandler)\n","filehandler.close()"],"metadata":{"id":"w1Yxcd9rr8mi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Numeral processing"],"metadata":{"id":"ePFsf-ohDIIm"}},{"cell_type":"code","source":["## Load data\n","if 'corpus_examples' in globals():\n","    del corpus_examples\n","\n","# file = open(data_dir + \"corpus_examples.pkl\", 'rb')\n","file = open(out_dir + \"corpus_examples.pkl\", 'rb')\n","corpus_examples = pickle.load(file)\n","file.close()"],"metadata":{"id":"ifqqRgTOseYw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def check_numeral(string):\n","  try:\n","      float(string)\n","      return True\n","  except ValueError:\n","      return False"],"metadata":{"id":"7wk0w8VeDtXJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n = np.random.choice(len(corpus_examples))\n","print(n)\n","example = corpus_examples[n]\n","\n","print(example['cont'])\n","print()\n","print('Length is:', len(example['cont']))\n","print('Numeral is:', example['cont'][example['num']])\n","print('Unit is: ', example['cont'][example['unit']])\n","print('Target is:', example['cont'][example['targ']])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3R5iI_tdstFT","executionInfo":{"status":"ok","timestamp":1670986677084,"user_tz":360,"elapsed":103,"user":{"displayName":"Chaochao Zhou","userId":"12741515649526346331"}},"outputId":"98d50ba8-1c78-4ec9-a4c6-f84d75daad98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["796\n","['mean' 'hospital' 'stay' 'were' '(' '3.6' '+/-' '1.7' ')' 'days' '.']\n","\n","Length is: 11\n","Numeral is: ['3.6']\n","Unit is:  ['days']\n","Target is: ['mean' 'hospital' 'stay']\n"]}]},{"cell_type":"code","source":["# text = example['cont'].copy()\n","# for (i, w) in enumerate(text):\n","#   if check_numeral(w) and i != example['num'][0]:\n","#     text[i] = '[num]'\n","\n","# text"],"metadata":{"id":"AJ0xcceVvdGb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# label = np.zeros((len(text),), dtype=int)\n","# label[example['unit']] = 1\n","# label[example['targ']] = 2\n","# label"],"metadata":{"id":"4Qf0_ILwwnQh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ## Numeral expansion\n","# # num_string = '-10000'\n","# num_string = text[example['num']][0]\n","# num_string = str(float(num_string))\n","# print(num_string)\n","\n","# num_chars = []\n","# for c in num_string:\n","#   if c == '-':\n","#     num_chars.append('[neg]')\n","#   elif c == '.':\n","#     num_chars.append('[dot]')\n","#   else:\n","#     num_chars.append(c)\n","\n","# num_chars"],"metadata":{"id":"BEYm6e9005ai"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# text_before = text[:example['num'][0]]\n","# print(text_before)\n","\n","# num_idx = [*range(len(text_before), len(text_before)+len(num_chars), 1)]\n","# print(num_idx)\n","\n","# text_after = text[example['num'][0]+1:]\n","# print(text_after)\n","\n","# text_new = np.array(list(text_before) + num_chars + list(text_after))\n","# print(text_new)"],"metadata":{"id":"-7momur75LpX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# label_before = label[:example['num'][0]]\n","# print(label_before)\n","# label_num = np.zeros((len(num_chars),), dtype=int)\n","# print(label_num)\n","# label_after = label[example['num'][0]+1:]\n","# print(label_after)\n","\n","# label_new = np.array(list(label_before) + list(label_num) + list(label_after), dtype=int)\n","# print(label_new)"],"metadata":{"id":"ZSty_mAL9pXz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print('Num is:', text_new[num_idx])\n","\n","# unit_idx = [i for (i, l) in enumerate(label_new) if l == 1]\n","# print('Unit is:', text_new[unit_idx])\n","\n","# targ_idx = [i for (i, l) in enumerate(label_new) if l == 2]\n","# print('Targ is:', text_new[targ_idx])\n","\n","# print()\n","# print('num_idx is:', num_idx)\n","# print('unit_idx is:', unit_idx)\n","# print('targ_idx is:', targ_idx)\n","\n","# idxes = num_idx + unit_idx + targ_idx\n","# print('min-max is:', min(idxes), max(idxes))\n","# print('range is:', max(idxes) - min(idxes) + 1)"],"metadata":{"id":"W19sMqaTD2Nx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# numLab = np.zeros((len(text_new),), dtype=int)\n","# numLab[num_idx] = 1\n","# print('Num is:', text_new[numLab == 1])"],"metadata":{"id":"d3Qcwdymjo66"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def proc_numeral_from_one_example(example):\n","  text = example['cont'].copy()\n","  for (i, w) in enumerate(text):\n","    if check_numeral(w) and i != example['num'][0]:\n","      text[i] = '[num]'\n","\n","  label = np.zeros((len(text),), dtype=int)\n","  label[example['unit']] = 1\n","  label[example['targ']] = 2\n","\n","  num_string = text[example['num']][0]\n","  num_string = str(float(num_string))\n","\n","  num_chars = []\n","  for c in num_string:\n","    if c == '-':\n","      num_chars.append('[neg]')\n","    elif c == '.':\n","      num_chars.append('[dot]')\n","    else:\n","      num_chars.append(c)\n","\n","  text_before = text[:example['num'][0]]\n","  num_idx = [*range(len(text_before), len(text_before)+len(num_chars), 1)]\n","  text_after = text[example['num'][0]+1:]\n","  text_new = np.array(list(text_before) + num_chars + list(text_after))\n","\n","  label_before = label[:example['num'][0]]\n","  label_num = np.zeros((len(num_chars),), dtype=int)\n","  label_after = label[example['num'][0]+1:]\n","  label_new = np.array(list(label_before) + list(label_num) + list(label_after), dtype=int)\n","\n","  numLab = np.zeros((len(text_new),), dtype=int)\n","  numLab[num_idx] = 1\n","\n","  unit_idx = [i for (i, l) in enumerate(label_new) if l == 1]\n","  targ_idx = [i for (i, l) in enumerate(label_new) if l == 2]\n","\n","  return {'text': text_new, 'label': label_new, 'numLab': numLab,\n","          'num_idx': num_idx, 'unit_idx': unit_idx, 'targ_idx': targ_idx}"],"metadata":{"id":"e3ay4gZiHAK6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_new = proc_numeral_from_one_example(example)\n","example_new"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nT4g6GjqIlBl","executionInfo":{"status":"ok","timestamp":1670986683227,"user_tz":360,"elapsed":242,"user":{"displayName":"Chaochao Zhou","userId":"12741515649526346331"}},"outputId":"ec573058-a231-4737-a045-a88bcd3f1ef9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'text': array(['mean', 'hospital', 'stay', 'were', '(', '3', '[dot]', '6', '+/-',\n","        '[num]', ')', 'days', '.'], dtype='<U8'),\n"," 'label': array([2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n"," 'numLab': array([0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0]),\n"," 'num_idx': [5, 6, 7],\n"," 'unit_idx': [11],\n"," 'targ_idx': [0, 1, 2]}"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["corpus_examples_new = []\n","max_window = 0\n","for example in corpus_examples:\n","  example_new = proc_numeral_from_one_example(example)\n","  corpus_examples_new.append(example_new)\n","\n","  idxes = example_new['num_idx'] + example_new['unit_idx'] + example_new['targ_idx']\n","  window = max(idxes) - min(idxes) + 1\n","  if window > max_window: max_window = window\n","\n","print(max_window)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5NZNcxEoMeOe","executionInfo":{"status":"ok","timestamp":1670986703889,"user_tz":360,"elapsed":492,"user":{"displayName":"Chaochao Zhou","userId":"12741515649526346331"}},"outputId":"b1957398-f861-414c-815a-ab4bee53d4d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["41\n"]}]},{"cell_type":"code","source":["corpus_examples_new[n]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ByocMRhNok1","executionInfo":{"status":"ok","timestamp":1670986705600,"user_tz":360,"elapsed":149,"user":{"displayName":"Chaochao Zhou","userId":"12741515649526346331"}},"outputId":"5e5f0268-65b0-470e-9124-fd5d52a8401a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'text': array(['mean', 'hospital', 'stay', 'were', '(', '3', '[dot]', '6', '+/-',\n","        '[num]', ')', 'days', '.'], dtype='<U8'),\n"," 'label': array([2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n"," 'numLab': array([0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0]),\n"," 'num_idx': [5, 6, 7],\n"," 'unit_idx': [11],\n"," 'targ_idx': [0, 1, 2]}"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["## Save data\n","# filehandler = open(data_dir + \"corpus_examples_num_proc.pkl\", \"wb\")\n","filehandler = open(out_dir + \"corpus_examples_num_proc.pkl\", \"wb\")\n","pickle.dump(corpus_examples_new, filehandler)\n","filehandler.close()"],"metadata":{"id":"OEyKN5s8OVa9"},"execution_count":null,"outputs":[]}]}